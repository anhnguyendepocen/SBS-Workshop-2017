\documentclass{beamer}
\newenvironment{changemargin}[2]{%
\begin{list}{}{%
\setlength{\topsep}{0pt}%
\setlength{\leftmargin}{#1}%
\setlength{\rightmargin}{#2}%
\setlength{\listparindent}{\parindent}%
\setlength{\itemindent}{\parindent}%
\setlength{\parsep}{\parskip}%
}%
\item[]}{\end{list}}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{url}
\usepackage{grffile}
\usetheme{Madrid}
\usecolortheme{beaver}
\setbeamertemplate{navigation symbols}{}
\titlegraphic{\includegraphics[width=5cm]{..//..//S-DS-VC-RGB.png}\hspace*{1cm}~%
   \includegraphics[width=5cm]{..//..//CompassLogo.jpg}
}
%\logo{\includegraphics[width=0.1\textwidth,keepaspectratio]{..//..//UOACrest.png}}
\author[SCC]{Statistical Consulting Centre}%\\
\institute[\href{mailto:consulting@stat.auckland.ac.nz}
  {consulting@stat.auckland.ac.nz}]{\href{mailto:consulting@stat.auckland.ac.nz}
  {consulting@stat.auckland.ac.nz}\\
  k.chang@auckland.ac.nz\\
%Statistical Consulting Centre\\
The Department of Statistics\\
The University of Auckland}
\title[Session 8 -- Advanced analysis]{NZSSN Courses: Introduction
to \texttt{R}}
\subtitle{Session 8 -- Advanced analysis}
\date{2 March, 2017}
\begin{document}
%\SweaveOpts{concordance=TRUE}
\maketitle
 
\begin{frame}[fragile]
  \frametitle{Linear regression}
<<echo = F>>=
options(continue = " ")
opts_chunk$set(comment=NA)
issp.df = read.csv("../../Data/issp.csv", stringsAsFactors = F)
gender.na <- which(issp.df$Gender == "NA, refused")
issp.df$Gender[gender.na] = NA
Q6.na <- which(issp.df$Q6 == "na, refused")
issp.df$Q6[Q6.na] = NA
issp.df$Q6 = factor(issp.df$Q6, levels = c("always wrong", "almost always wrong", "only sometimes wrong", "not wrong at all", "cant choose, dk"))
Q7.na <- which(issp.df$Q7 == "na, refused")
issp.df$Q7[Q7.na] <- NA
issp.df$Q7 = factor(issp.df$Q7, levels = c("always wrong", "almost always wrong", "only sometimes wrong", "not wrong at all", "cant choose, dk"))
Q8.na <- which(issp.df$Q8 == "na, refused")
issp.df$Q8[Q8.na] <- NA
issp.df$Q8 = factor(issp.df$Q8, levels = c("always wrong", "almost always wrong", "only sometimes wrong", "not wrong at all", "cant choose, dk"))
Q1.na <- which(issp.df$Q1 == "na, refused" | issp.df$Q1 == "can't choose, dk")
issp.df$Q1[Q1.na] <- NA
issp.df$Q1 = factor(issp.df$Q1, 
                    levels = c("strongly agree", 
                    "agree", "neither agree nor dis", 
                    "disagree", "strongly disagree"))
issp.df$age.group = ifelse(issp.df$Age<=35, "Under 35", 
                           ifelse(issp.df$Age <= 60, "36 to 60", "Over 61"))
issp.df$age.group = factor(issp.df$age.group, 
                           levels = c("Under 35", 
                                      "36 to 60", 
                                      "Over 61"))
issp.df$Q2 <- ifelse(issp.df$Q2 == "cant choose, dk" | issp.df$Q2 == "na, refused", NA, issp.df$Q2)
issp.df$Q2 = factor(issp.df$Q2, 
                    levels = c("strongly agree", 
                    "agree", "neither agree nor dis", 
                    "disagree", "strongly disagree"))

issp.df$Q3 <- ifelse(issp.df$Q3 == "cant choose, dk" | 
                     issp.df$Q3 == "na, refused", 
                     NA, issp.df$Q3)
issp.df$Q3 = factor(issp.df$Q3, 
                    levels = c("strongly agree", 
                    "agree", "neither agree nor dis", 
                    "disagree", "strongly disagree"))
issp.df$Q4 <- ifelse(issp.df$Q4 == "cant choose, dk" | 
                     issp.df$Q4 == "na, refused", 
                     NA, issp.df$Q4)
issp.df$Q4 = factor(issp.df$Q4, 
                    levels = c("strongly agree", 
                    "agree", "neither agree nor dis", 
                    "disagree", "strongly disagree"))
Q1.lik <- as.numeric(issp.df$Q1)
Q2.lik <- as.numeric(issp.df$Q2)
Q3.lik <- as.numeric(issp.df$Q3)
Q4.lik <- as.numeric(issp.df$Q4)
total.lik <- Q1.lik + Q2.lik + Q3.lik + Q4.lik
scale.df <- data.frame(cbind(Q1.lik, Q2.lik, Q3.lik, Q4.lik, total.lik))
issp.df$Income <- ifelse(issp.df$Income 
                         == "NAV; NAP No own income",
                         NA, issp.df$Income)
issp.df$total.lik <- scale.df$total.lik
issp.df$Q5 = with(issp.df, ifelse(Q5 == "can t choose, dk" 
                          | Q5 == "NA, refused", NA, Q5))
issp.df$Gender = factor(issp.df$Gender)
Q5.age.tab <- with(issp.df, table(Q5, age.group))
Q5.age.df <- data.frame(matrix(0, nrow = prod(dim(Q5.age.tab)), ncol = length(dim(Q5.age.tab))+1))
colnames(Q5.age.df) = c("age.group", "Q5", "freq")
Q5.age.df$freq = c(Q5.age.tab[1, ], Q5.age.tab[2, ])
Q5.age.df$age.group = names(c(Q5.age.tab[1, ], Q5.age.tab[2, ]))
Q5.age.df$Q5 = rep(rownames(Q5.age.tab), c(3, 3))
Q5.age.df$age.group = factor(Q5.age.df$age.group, levels = colnames(Q5.age.tab))
Q5.age.df$Q5 = factor(Q5.age.df$Q5, levels = rownames(Q5.age.tab))
@
\verb|lm(y~x)| is used for linear regression.
  \begin{itemize}
  \item \texttt{y}, the response variable.
  \item \texttt{x}, the explanatory variable.   
  \item There can be more than one explanatory variable, called {\em multiple} linear regression. 
  \item Both response variable and explanatory variable(s) should be numeric, it is {\em generalised} linear regression.
  \end{itemize}
\end{frame} 

\begin{frame}[fragile]
\frametitle{Simple linear regression}
When there is only one predictor variable (e.g. Age) in our linear regression, we refer to this as {\em simple} linear regression.
<<fig.align ='center', echo = F, out.width = '0.6\\linewidth'>>=
with(issp.df, plot(Age, total.lik))
@
\end{frame} 

\begin{frame}[fragile]
\frametitle{Simple linear regression}
\begin{itemize}
 \item The relationship between age and total score appears weakly negative, i.e. total score decreases with age.
 \item Let's carry out the linear regression of Age on total score, i.e.
<<>>=
try.lm <- with(issp.df, lm(total.lik~Age))
@
\end{itemize}
\end{frame} 

\begin{frame}[fragile]
\frametitle{Simple linear regression}
\begin{scriptsize}
<<>>=
summary(try.lm)
@
\end{scriptsize}
\end{frame} 


\begin{frame}[fragile]
\frametitle{Simple linear regression}
<<echo = F>>=
summary(try.lm)$coef
@
\begin{itemize}
\item The estimated intercept is \Sexpr{round(coef(try.lm)[1], 2)}. There is very strong evidence that this is not zero ($p$-value $< 0.0001$).
\item The estimated slope is \Sexpr{round(coef(try.lm)[2], 2)}. There is very strong evidence that this is not zero ($p$-value $< 0.0001$).
\item The fitted line is \texttt{total.lik} = \Sexpr{round(coef(try.lm)[2], 2)} $\times$ \texttt{Age} + \Sexpr{round(coef(try.lm)[1], 2)}
\item For every one year increase in age, the mean total score decreases by \Sexpr{abs(round(coef(try.lm)[2], 2))} units on the likert scale.
\end{itemize}
\end{frame} 

\begin{frame}[fragile]
\frametitle{Check the fit: Residual plots}
<<fig.align ='center', out.width = '0.6\\linewidth'>>=
plot(residuals(try.lm))
@
\end{frame} 

\begin{frame}[fragile]
\frametitle{Are the residuals approximately normal?}
<<fig.align ='center', out.width = '0.6\\linewidth'>>=
qqnorm(residuals(try.lm))
qqline(residuals(try.lm), col = 2, lwd = 2)
@
\end{frame} 


\begin{frame}[fragile]
\frametitle{Conclusion}
\begin{itemize}
\item The linear relationship between age and total score is statistically significant.
\item Total score is negatively related to age.
\end{itemize}
\end{frame}


\begin{frame}[fragile]
  \frametitle{Add the fitted line}
<<eval = F, tidy = F>>=
with(issp.df, plot(Age, total.lik))
abline(try.lm, col = 2)
@
<<fitted, include = F, tidy = F>>=
with(issp.df, plot(Age, total.lik))
abline(try.lm, col = 2)
@
\begin{figure}[h]
  \vspace{-20pt}
  \centering
  \includegraphics[height = 0.6\textwidth, keepaspectratio]{Figure/fitted}
  %\vspace{-20pt}
  %\caption{Boxplots of PM10 in 2006--2012}
  \label{fig:fitted}
\end{figure}
\end{frame} 

\begin{frame}[fragile]
\frametitle{What if the response variable is \emph{not} continuous?}
So far, we have considered methods for analysing response variables 
measured on a continuous scale.\\
\vspace{0.2cm}
Often, measurements are:
  \begin{itemize}
\item \emph{Counts} per unit time, e.g. number of hours worked in a working week.
\item \emph{Binary} responses, e.g. Gender.
\item \emph{Generalised} linear models: \emph{Poisson} (counts) and \emph{Logistic} (binary) regression
\item \emph{Today} logistic regression \emph{only}
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Logistic regression}
\begin{itemize}
\item Relates a \textcolor{blue}{\emph{binary}} \emph{response variable}
to a continuous and/or categorical variable
\item Let's illustrate by example using \texttt{issp.df}.
\begin{itemize}
\item Consider the variable \texttt{Q5} with values `\texttt{be obedient}' and '\texttt{think themselves}'.
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Logistic regression}
\begin{center}
\textbf{Question} \\
Is \texttt{Age} a useful indicator of choosing `\texttt{being obedient}' as important in preparing for children for life? \\[0.2cm]
\textbf{How do we answer this?} \\
By relating the \emph{probability} of \texttt{being obedient} 
to \texttt{Age}.
\end{center}  
\begin{itemize}
\item Linear regression is \emph{not} suitable here because:
\begin{itemize}
\item It assumes the response variable (\texttt{Q5}) takes values from $-\infty$ to $+\infty$.\\
\item But \texttt{Q5} takes only two values, namely \texttt{being obedient} or \texttt{think themselves}!
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Relating a probability to an explanatory variable}
Let:
\begin{itemize}
  \item $p = \Pr\left(\mathtt{Q5} = \mathtt{being}\mbox{ }\mathtt{obedient} \right)$
  \item $1-p = \Pr\left(\mathtt{Q5} = \mathtt{think}\mbox{ }\mathtt{themselves} \right)$
\end{itemize}
\vspace{0.2cm}
\textbf{Definition:} The \emph{odds} that a respondent of \texttt{Q5} chooses \texttt{being\mbox{ }obedient} is
\[ \text{odds} = \frac{p}{1-p}. \]
\begin{itemize}
\item The \emph{odds} of an event (i.e.  $\mathtt{Q5} = \mathtt{being}\mbox{ } \mathtt{obedient}$) 
tells us how likely that event is to occur relative to it not
occurring.
\item To relate $p$ to an explanatory variable, we need the \textbf{\emph{log-odds}}, i.e.
\end{itemize}
\[ \log\left(\frac{p}{1-p}\right) = \mathtt{Intercept} + \mathtt{Slope} \times \mathtt{Age}. \]
\begin{itemize}
\item $\log\left(\frac{p}{1-p}\right)$ is known as the \emph{logit} transformation
\end{itemize}
\end{frame}



\begin{frame}[fragile]
\frametitle{GLMs in \texttt{R}: \texttt{glm()}}
\texttt{glm(formula, family, ...)}
\begin{itemize}
\item \texttt{formula:} Similar format as \texttt{lm()}; response
variable and explanatory variable(s) separated by \verb|~|.
\item \texttt{family:} Use \texttt{family = binomial} for logistic
regression.
\item \texttt{...} See the help file of \texttt{glm} (\texttt{?glm})
for other arguments.
\end{itemize}
%By default, \texttt{R} chooses the highest level as the response
\end{frame}


\begin{frame}[fragile]
\frametitle{Logistic regression: Example}
Suppose we want to find out whether older people are more likely to consider {\em being obedient} as more important in preparing children for life than is {\em thinking for themselves}.\\\vspace{0.5cm}

Statisically speaking, we want to test whether the probability of choosing ``\texttt{be obedient}'' in \texttt{Q5} increases/decreases/does not change with \texttt{Age}.
\end{frame}


\begin{frame}[fragile]
\frametitle{Logistic regression: Example}
\begin{itemize}
  \item Declare the response variable \texttt{Q5} as a integer/numeric.
  \item \texttt{be obedient} is assigned the numeric value 1 and 
        \texttt{think themselves} is assigned numeric value 0.
  \item It follows, therefore, that:
  \begin{enumerate}    
    \item $p=\Pr(\mathtt{be\mbox{ }obedient})$
    \item $p/(1-p)$ is the odds of participants selecting 
          ``being obedient'' relative to selecting 
          ``thinking for themselves'' as being important in preparing
          children for life.
  \end{enumerate}
\end{itemize}
Note: Here, the explanatory variable Age is integer/numeric.
\end{frame}


\begin{frame}[fragile]
\frametitle{GLMs in \texttt{R}: \texttt{glm()}}
<<>>=
## class of Q5?
class(issp.df$Q5)

## Convert Q5 to a variable of type 'numeric'
issp.df$Q5 <- ifelse(issp.df$Q5 == "be obedient", 1, 0)

## Numeric values of Q5?
class(issp.df$Q5)
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Logistic regression: Example}
Fit the model with \texttt{glm()}
\vspace{-2mm}
<<tidy = F>>=
try.glm <- with(issp.df, glm(Q5~Age, 
                             family = binomial))
@
\begin{itemize}
\item \texttt{family = binomial}, logistic regression.
\end{itemize}
\vspace{-2mm}
\begin{scriptsize}
<<results='hide'>>=
summary(try.glm)
@
\end{scriptsize}
\vspace{-5mm}
\begin{scriptsize}
<<echo=FALSE>>=
summary(try.glm)
@
\end{scriptsize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Logistic regression: Example}
<<echo = F>>=
summary(try.glm)$coef
@
\begin{eqnarray*}
\text{logit}(\text{be obedient}) & = & \Sexpr{round(coef(try.glm)[1], 2)} + \Sexpr{round(coef(try.glm)[2], 2)} \times \text{Age}.\\
\text{Odds}(\text{be obedient}) & = & e^{\Sexpr{round(coef(try.glm)[1], 2)} + \Sexpr{round(coef(try.glm)[2], 2)} \times \text{Age}}\\
\text{Probability}(\text{be obedient}) & = & \frac{e^{\Sexpr{round(coef(try.glm)[1], 2)} + \Sexpr{round(coef(try.glm)[2], 2)} \times \text{Age}}}{1 + e^{\Sexpr{round(coef(try.glm)[1], 2)} + \Sexpr{round(coef(try.glm)[2], 2)} \times \text{Age}}}
\end{eqnarray*}
\end{frame}

\begin{frame}[fragile]
\frametitle{Prediction from the model}
<<tidy=FALSE>>=
# Logit scale, usually referred to as the 
# 'linear predictor' scale
lp <- predict(try.glm, data.frame(Age = 50))
lp

# Calculate the odds
exp(lp)
@
Interpretation: A 50-year old is \textbf{\Sexpr{round(exp(lp),1)} times} likely to consider {\em being obedient} important preparation for life than {\em thinking for oneself}. Or, a 50-year old is \textbf{\Sexpr{round(1/exp(lp),1)} times more} likely to {\em thinking for oneself} than {\em being obedient}.
\end{frame}

\begin{frame}[fragile]
\frametitle{Prediction from the model}
<<>>=
#Probability scale
predict(try.glm, data.frame(Age = 50), type = "response")
@
Interpretation: The probability that a 50-year old considers {\em being obedient} important preparation for life is \Sexpr{predict(try.glm, data.frame(Age = 50), type = "response")}.
\end{frame}

\begin{frame}[fragile]
\frametitle{Putting prediction into context}
<<tidy = F>>= 
#Probability with standard error
predict(try.glm, data.frame(Age = 50), 
type = "response", se.fit = TRUE)
@
\end{frame}

\begin{frame}[fragile]
\frametitle{Categorical explanatory variables}
\begin{scriptsize}
<<tidy = F>>= 
try.glm2 <- with(issp.df, glm(Q5~age.group, family = binomial))
anova(try.glm2, test = "Chisq")
@
\end{scriptsize}
Analysis of deviance table for a \texttt{glm()} object (generated using \texttt{anova()}) is analogous to ANOVA table for an \texttt{lm()} object.
\end{frame}


\begin{frame}[fragile]
\frametitle{Categorical explanatory variables}
\begin{scriptsize}
<<tidy = F>>= 
anova(try.glm2, test = "Chisq")
@
\end{scriptsize}
We have extremely strong evidence that at least one age group has different log-odds of choosing "be obedient" from the other age groups.
\end{frame}


\begin{frame}[fragile]
\frametitle{Categorical explanatory variables}
\begin{scriptsize}
<<>>= 
summary(try.glm2)
@
\end{scriptsize}
\end{frame}


\begin{frame}[fragile]
\frametitle{Categorical explanatory variables}
<<echo = F, size = "small">>= 
summary(try.glm2)$coef
@
\begin{itemize}
  \item \texttt{(Intercept)} corresponds to the reference age group, namely
  ``Under 35'' which is the one that is {\em not} listed!
  \item So, all subsequent rows of this table are hypothesis tests of the
  log-odds of the named age group relative to the reference group being
  zero, i.e.
  \begin{enumerate}
    \item There is extremely strong evidence ($p$-value $<<$ 0.0001) that
    the log-odds of choosing {\em being obedient} for the ``Over 61'' age
    group is higher than ``Under 35'' ($p$-value $<$ 0.0001).
    \item There is no evidence ($p$-value = 0.098) that the log-odds of
    choosing {\em being obedient} for ``36 to 60'' is different from
    ``Under 35'' .
  \end{enumerate}
\end{itemize}
\end{frame}


\begin{frame}[fragile]
\frametitle{Compare "Over 61" with "36 to 60"}
\begin{itemize}
\item Create another factor for age group with different reference level.
<<tidy = F>>= 
age.refac <- factor(as.character(issp.df$age.group), 
   levels = c("Over 61", "36 to 60", "Under 35"))
@
\item Re-fit the model.
<<tidy = F>>=
try.glm3 <- glm(Q5~age.refac, family = binomial,
                data=issp.df)
@
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Compare "Over 61" with "36 to 60"}
<<eval = F>>=
summary(try.glm3)
@
<<echo = F, size = "small" >>=
summary(try.glm3)$coef
@
There is extremely strong evidence that the log-odds of choosing {\em being obedient} for the ``36 to 60'' age group is \emph{lower} than the ``Over 61'' age group.
\end{frame}

\begin{frame}[fragile]
  \frametitle{Summary}
  \begin{itemize}
  \item Linear regression
  \item Logistic Regression
  \end{itemize}
\end{frame}

\end{document}     
